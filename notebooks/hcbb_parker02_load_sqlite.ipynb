{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SUMMARY\n",
    "### 4 SQLite Tables:\n",
    "#### 1 - npidata - only filtered to correct taxonomy and zip codes\n",
    "#### 2 - taxonomy - no filtering\n",
    "#### 3 - hop_teaming - no filtering\n",
    "#### 4 - filtered_hop_teaming - Filtered to correct entity types, transaction counts, and wait times\n",
    "\n",
    "## VERONICA - Only pay attention to cells directly below a header with * Title Here *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## * Load SQLite Table 1: npidata *\n",
    "### Filter to Nashville zip code and Primary Taxonomy; Clean Columns\n",
    "### VERONICA - The taxonomy code is complex, but correct. Maeva did it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Zip codes (keep leading zeros, filter to zip codes in the Nashville CBSA)\n",
    "zips = pd.read_excel(\"../data/ZIP_CBSA_122017.xlsx\", converters={'zip': lambda x: str(x)})\n",
    "zips = zips[zips['cbsa'] == 34980]\n",
    "\n",
    "with sqlite3.connect('../data/hcbb.sqlite') as db:\n",
    "\n",
    "    npidata_raw = pd.read_csv(\"../data/npidata_pfile_20050523-20210207.csv\", chunksize = 10000)\n",
    "    for chunk in tqdm(npidata_raw):\n",
    "\n",
    "        npidata = pd.concat([\n",
    "            chunk[['NPI']],\n",
    "            # Entity Type Code: 1 = Provider (doctors, nurses, etc.) / 2 = Facility (Hospitals, Urgent Care, Doctors Offices) \n",
    "            chunk[['Entity Type Code']],\n",
    "            # Entity Name: Either First/Last or Organization or Other Organization Name contained in the following fields:\n",
    "            chunk.loc[:, 'Provider Organization Name (Legal Business Name)':'Provider Credential Text'],\n",
    "            # Address: Business Practice Location (not mailing), contained in the following fields:\n",
    "            chunk.loc[:, 'Provider First Line Business Practice Location Address':'Provider Business Practice Location Address Postal Code'],\n",
    "        ], axis=1)\n",
    "\n",
    "        npi_taxonomy = pd.concat([\n",
    "            chunk[['NPI']],\n",
    "            # The provider's taxonomy code, which is contained in one of the 'Healthcare Provider Taxonomy Code*' columns\n",
    "            chunk[chunk.columns[pd.Series(chunk.columns).str.startswith('Healthcare Provider Taxonomy Code_')]],\n",
    "            chunk[chunk.columns[pd.Series(chunk.columns).str.startswith('Healthcare Provider Primary Taxonomy Switch_')]]\n",
    "        ], axis=1)\n",
    "\n",
    "        # Pivot from wide to long format\n",
    "        npi_taxonomy = pd.wide_to_long(\n",
    "            npi_taxonomy,\n",
    "            stubnames=['Healthcare Provider Taxonomy Code', 'Healthcare Provider Primary Taxonomy Switch'],\n",
    "            i=['NPI'], \n",
    "            j='primary_taxonomy_index',\n",
    "            sep=\"_\"\n",
    "        )\n",
    "\n",
    "        # Only keep the primary taxonomy\n",
    "        npi_taxonomy = npi_taxonomy[npi_taxonomy['Healthcare Provider Primary Taxonomy Switch'] == 'Y']\n",
    "\n",
    "        # Housekeeping\n",
    "        npi_taxonomy = npi_taxonomy.reset_index()\\\n",
    "            .drop(columns=['primary_taxonomy_index', 'Healthcare Provider Primary Taxonomy Switch'])\\\n",
    "            .rename({ 'Healthcare Provider Taxonomy Code': 'taxonomy_code' }, axis=1)\n",
    "\n",
    "        npidata = npidata.merge(\n",
    "            npi_taxonomy,\n",
    "            how='left',\n",
    "            on='NPI'\n",
    "        )\n",
    "\n",
    "        # Rename columns\n",
    "        npidata = npidata.reset_index().rename({\n",
    "            'NPI': 'npi',\n",
    "            'Entity Type Code': 'entity_type_code',\n",
    "            'Provider Organization Name (Legal Business Name)': 'provider_org_name',\n",
    "            'Provider Last Name (Legal Name)': 'provider_last_name',\n",
    "            'Provider First Name': 'provider_first_name',\n",
    "            'Provider Middle Name': 'provider_middle_name',\n",
    "            'Provider Name Prefix Text': 'provider_name_prefix',\n",
    "            'Provider Name Suffix Text': 'provider_name_suffix',\n",
    "            'Provider Credential Text': 'provider_credential',\n",
    "            'Provider First Line Business Practice Location Address': 'provider_business_address_1',\n",
    "            'Provider Second Line Business Practice Location Address': 'provider_business_address_2',\n",
    "            'Provider Business Practice Location Address City Name': 'provider_business_city',\n",
    "            'Provider Business Practice Location Address State Name': 'provider_business_state',\n",
    "            'Provider Business Practice Location Address Postal Code': 'provider_business_zip'\n",
    "        }, axis=1)\n",
    "\n",
    "        # Create Zip5 column to merge down the road\n",
    "        npidata['provider_business_zip5'] = [str(i)[0:5] for i in npidata['provider_business_zip']]\n",
    "        \n",
    "        # Correct data types\n",
    "        npidata['npi'] = npidata['npi'].astype(str)\n",
    "        npidata['entity_type_code'] = npidata['entity_type_code'].astype(str).str.split('.').str[0]\n",
    "        npidata['provider_business_zip'] = npidata['provider_business_zip'].astype(str).str.split('.').str[0]\n",
    "        npidata['provider_business_zip5'] = npidata['provider_business_zip5'].astype(str).str.split('.').str[0]\n",
    "        npidata = npidata[npidata['provider_business_zip5'].isin(zips['zip'])]\n",
    "        \n",
    "        # Remove unneeded columns\n",
    "        npidata = npidata.drop('index', axis=1)\n",
    "        \n",
    "        # Filter to Nashville zips, TN state\n",
    "        npidata = npidata[(npidata['provider_business_zip5'].isin(zips['zip'])) & \n",
    "                          (npidata['provider_business_state'].isin(['TN', 'TENNESSEE']))]\n",
    "\n",
    "        npidata.to_sql('npidata', db, if_exists = 'append', index = False)                           \n",
    "\n",
    "    print('task done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removed Table to make an update."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#create a database or connect to an existing one\n",
    "db = sqlite3.connect('../data/hcbb.sqlite')\n",
    "#if you need to edit the database...\n",
    "cursor = db.cursor()\n",
    "#Drop the table and return a line that says that it's gone\n",
    "cursor.execute(\"DROP TABLE filtered_hop_teaming\")\n",
    "print(\"Table dropped...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test to confirm the table loaded.\n",
    "with sqlite3.connect('../data/hcbb.sqlite') as db :\n",
    "    query = \"\"\"\n",
    "    SELECT COUNT(*) AS count_all\n",
    "    FROM npidata;\n",
    "    \"\"\" \n",
    "    \n",
    "    test = pd.read_sql(query, db)\n",
    "\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## * Load SQLite Table 2: taxonomy *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sqlite3.connect('../data/hcbb.sqlite') as db:   \n",
    "    taxonomy = pd.read_csv(\"../data/nucc_taxonomy_210.csv\")\n",
    "    taxonomy = taxonomy[['Code', 'Grouping', 'Classification', 'Specialization']]\n",
    "    taxonomy.columns = ['taxonomy_code', 'grouping', 'classification', 'specialization']\n",
    "    taxonomy.to_sql('taxonomy', db, if_exists = 'append', index = False)  \n",
    "    \n",
    "    print('task done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## * Load SQLite Table 3, hop_teaming *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in tqdm(pd.read_csv(\"../data/DocGraph_Hop_Teaming_2017.csv\", chunksize = 10000)):\n",
    "    # Append the chunk to a hop_teaming table\n",
    "    chunk.to_sql(\n",
    "        'hop_teaming', # The table name\n",
    "        db, # The database\n",
    "        if_exists = 'append', \n",
    "        index = False # Do not include the pandas index column\n",
    "    )\n",
    "\n",
    "#When done, print done\n",
    "print('Task done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Listing currently existing tables in the database\n",
    "with sqlite3.connect('../data/hcbb.sqlite') as db :\n",
    "    query = \"\"\"\n",
    "        SELECT name\n",
    "        FROM sqlite_master \n",
    "        WHERE type ='table' \n",
    "        AND name NOT LIKE 'sqlite_%';\n",
    "        \"\"\" \n",
    "\n",
    "    test_df = pd.read_sql(query, db)\n",
    "\n",
    "display(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## * Filter by entity type *\n",
    "### Filter from_npi to be entity type 1 and to_npi to be entity type 2, to be used for SQLite Table 4.\n",
    "#### NOTE: The following cell codes runs in ~5-10 minutes. Set to markdown for security."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sqlite3.connect('../data/hcbb.sqlite') as db :\n",
    "    query = \"\"\"\n",
    "    WITH npi_entity_type_1 AS (\n",
    "        SELECT npi\n",
    "        FROM npidata \n",
    "        WHERE entity_type_code = 1\n",
    "    ), npi_entity_type_2 AS (\n",
    "        SELECT npi\n",
    "        FROM npidata \n",
    "        WHERE entity_type_code = 2\n",
    "    )\n",
    "    SELECT *\n",
    "    FROM hop_teaming\n",
    "    WHERE from_npi IN npi_entity_type_1\n",
    "    AND to_npi IN npi_entity_type_2\n",
    "    \"\"\"\n",
    "    \n",
    "    filtered_hop_teaming = pd.read_sql(query, db)\n",
    "\n",
    "display(filtered_hop_teaming.shape)\n",
    "display(filtered_hop_teaming.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## * Filter by transaction count and average day wait *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter so that the transaction_count is >= 50 and average_day_wait <= 50\n",
    "filtered_hop_teaming = filtered_hop_teaming[\n",
    "    (filtered_hop_teaming[\"transaction_count\"] >= 50) &\n",
    "    (filtered_hop_teaming[\"average_day_wait\"] <= 50)\n",
    "]\n",
    "\n",
    "display(filtered_hop_teaming.shape)\n",
    "display(filtered_hop_teaming.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## * Load SQLite Table 4, filtered_hop_teaming *\n",
    "\n",
    "### IMPORTANT! This loading into the database should only be run once. If you run this multiple times, it will create duplicate entries in the database. For the security of not re-running this code by accident, the code here is converted into markdown. If you need to rebuild the database, delete the data/hcbb.sqlite file and re-run this cell as code. You will also need to make sure to re-run any other related scripts that builds other tables in the database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with sqlite3.connect('../data/hcbb.sqlite') as db:\n",
    "    filtered_hop_teaming.to_sql(\n",
    "        'filtered_hop_teaming', \n",
    "        db, \n",
    "        if_exists = 'append', \n",
    "        index = False)\n",
    "\n",
    "    # When done, print done\n",
    "    print('Task done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_hop_teaming.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
